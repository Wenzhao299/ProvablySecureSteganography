# ProvablySecureSteganography

**Language**: [中文](README.md) | [English](README_en.md)

This repository contains experimental code for text steganography with large language models (LLMs). It supports embedding and extraction with multiple steganography methods, plus multi-GPU batch processing, single-sample testing, PPL evaluation, and capacity/speed benchmarking.

## Key Features

- Multi-GPU batch steganography and extraction: `stego_parallel.py`
- Single-sample steganography and extraction: `stego_single.py`
- Perplexity evaluation: `evaluate_ppl.py`
- Capacity and speed evaluation: `evaluate_capacity_speed.py`
- Supported methods: `ac`, `meteor`, `adg`, `discop`, `imec`, `sparsamp`

## Implemented Methods and Papers

- `ac`: [Neural Linguistic Steganography](https://aclanthology.org/D19-1115/) (ACL 2019)
- `meteor`: [METEOR: Neural Linguistic Steganography with Self-Adjusting Arithmetic Coding](https://dl.acm.org/doi/10.1145/3460120.3484550) (ACM CCS 2021)
- `adg`: [Provably Secure Generative Linguistic Steganography](https://aclanthology.org/2021.findings-acl.268/) (ACL Findings 2021)
- `discop`: [Discop: Provably Secure Steganography in Practice based on "Distribution Copies"](https://ieeexplore.ieee.org/document/10179287) (IEEE S&P 2023)
- `imec`: [Near-Optimal Practical and Secure Text Steganography](https://iclr.cc/virtual/2023/poster/11490) (ICLR 2023)
- `sparsamp`: [Provably Secure Text Steganography via Sparsification and Sampling](https://www.usenix.org/conference/usenixsecurity25/presentation/wang-yaofei) (USENIX Security 2025)

## Project Structure

```text
.
├── config.py                     # Central config: model paths, defaults, output path helpers
├── utils.py                      # Shared utilities: model loading, method dispatch, sampling/math helpers
├── stego_parallel.py             # Multi-GPU batch pipeline entrypoint
├── stego_single.py               # Single-sample pipeline entrypoint
├── evaluate_ppl.py               # PPL evaluation
├── evaluate_capacity_speed.py    # Capacity/speed evaluation
├── pss/                          # Implementations of steganography algorithms
└── context_movie.csv             # Example input data
```

## Environment

Core dependencies imported by scripts:

- `torch`
- `transformers`
- `numpy`
- `scipy`
- `tqdm`
- `bitarray`

## Model and Configuration

Model paths and defaults are centralized in `config.py`:

- `MODEL_PATH_MAP`
- `SUPPORTED_MODEL_NAMES`
- `DEFAULT_*` (for example, `DEFAULT_MAX_TOKENS`, `DEFAULT_TEMP`)

To use local model directories, update `MODEL_PATH_MAP` in `config.py`.

## Input Data Format

The parallel script reads CSV by default and expects at least two columns:

- Column 1: `id`
- Column 2: `context`

See `context_movie.csv` for an example.

## Usage

### 1) Multi-GPU Batch Steganography and Extraction

```bash
conda run -n env_ac python stego_parallel.py \
  --method meteor \
  --model_name qwen2.5 \
  --input_csv context_movie.csv \
  --max_contexts 1000 \
  --max_tokens 200
```

Notes:

- `message_bits` are randomly generated by default (default length is `max_tokens * 16`).
- Parallel mode requires CUDA GPUs (the script spawns processes based on detected GPU count).
- Resume is supported: processed `id`s in existing outputs/temp shards are automatically skipped.

Outputs:

- Stego results: `results_parallel/{dataset}/{method}.jsonl`
  - One JSON per line: `{"id": "...", "text": "..."}`
- Temporary shard directory: `results_parallel/{dataset}/.tmp_{method}` (cleaned up after merge)

### 2) Single-Sample Steganography and Extraction

```bash
conda run -n env_ac python stego_single.py \
  --method meteor \
  --model_name qwen2.5 \
  --input_text "Tell a short story about a rabbit." \
  --message_bits 010101110011 \
  --max_tokens 200
```

Outputs:

- Stego text records: `results_single/{method}.jsonl` (append mode)
- One JSON per line with fields: `model_name`, `input_text`, `message_bits`, `text`
- Console prints embedded/extracted bit strings and match status.

### 3) PPL Evaluation

```bash
conda run -n env_ac python evaluate_ppl.py \
  --model qwen2.5 \
  --dataset movie \
  --method meteor
```

Default input: `results_parallel/{dataset}/{method}.jsonl`

Output directory: `results_parallel/{dataset}/ppl/`

- Per-sample PPL: `results_parallel/{dataset}/ppl/{method}.jsonl`
  - One JSON per line: `{"id": "...", "text": "...", "ppl": 12.34}`
- Summary stats: `results_parallel/{dataset}/ppl/stats_{method}.jsonl`
  - Single-line JSON: `{"average_ppl": ..., "max_ppl": ..., ...}`

### 4) Capacity and Speed Evaluation

```bash
conda run -n env_ac python evaluate_capacity_speed.py \
  --model_name qwen2.5 \
  --input_csv context_movie.csv \
  --dataset movie \
  --max_contexts 1000 \
  --max_tokens 200
```

Output: `results_parallel/{dataset}/capacity_speed_{model_name}.jsonl`

- One JSON per line with fields: `model_name`, `dataset`, `input_csv`, `max_contexts`, `max_tokens`, `method`, `avg_capacity`, `avg_speed`, `processed_count`

## Common Arguments

- `--method`: steganography method (required)
- `--model_name`: `gpt2` / `qwen2.5` / `llama3.2`
- `--model_path`: custom model path (overrides `config.py`)
- `--max_tokens`: max number of generated tokens
- `--top_p` / `--top_k` / `--temp`: sampling parameters
- `--seed`: random seed
- `--ac_precision`, `--meteor_reorder`, `--imec_block_size`, `--sparsamp_block_size`: method-specific parameters

## License

This project is distributed under the **MIT License**.

- Permits commercial use, modification, distribution, and private use
- Simple and practical for both research and engineering reuse

See the `LICENSE` file for details.
